{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-28T09:18:59.990312100Z",
     "start_time": "2024-02-28T09:18:59.952308100Z"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://username:password@host:1278'\n",
    "os.environ['https_proxy'] = 'http://username:password@host:1278'\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''\n",
    "os.environ[\"SERPAPI_API_KEY\"] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过自然语言执行SQL命令"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "95aa4161b5cf085d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "db = SQLDatabase.from_uri(\"mysql+pymysql://username:password@127.0.0.1/ruoyi\")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)\n",
    "db_chain.run(\"How many sys role are there?\")\n",
    "db_chain.run(\"Which sys role are there?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T09:19:10.348177900Z",
     "start_time": "2024-02-28T09:18:59.984307200Z"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "id": "76d8982ccca4c345",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "7fffd74d52bc85ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 初始化 MessageHistory 对象\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "# 给 MessageHistory 对象添加对话内容\n",
    "history.add_ai_message(\"你好！\")\n",
    "history.add_user_message(\"中国的首都是哪里？\")\n",
    "\n",
    "# 执行对话\n",
    "ai_response = chat(history.messages)\n",
    "print(ai_response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T07:38:31.275596700Z",
     "start_time": "2024-02-28T07:38:29.247575900Z"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "id": "b2dac2e39d070a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "自定义agent中所使用的工具"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "2efc640783e61beb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMMathChain, SerpAPIWrapper\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 初始化搜索链和计算链\n",
    "search = SerpAPIWrapper()\n",
    "llm_math_chain = LLMMathChain(llm=llm, verbose=True)\n",
    "\n",
    "# 创建一个功能列表，指明这个 agent 里面都有哪些可用工具，agent 执行过程可以看必知概念里的 Agent 那张图\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# 初始化 agent\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# 执行 agent\n",
    "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T07:35:01.616433400Z",
     "start_time": "2024-02-28T07:34:49.419343400Z"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "id": "1cce85eccea63fda",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "爬取网页并输出JSON数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "5652809f1babc748"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMRequestsChain, LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "template = \"\"\"在 >>> 和 <<< 之间是网页的返回的HTML内容。\n",
    "网页是新浪财经A股上市公司的公司简介。\n",
    "请抽取参数请求的信息。\n",
    "\n",
    ">>> {requests_result} <<<\n",
    "请使用如下的JSON格式返回数据\n",
    "{{\n",
    "  \"company_name\":\"a\",\n",
    "  \"company_english_name\":\"b\",\n",
    "  \"issue_price\":\"c\",\n",
    "  \"date_of_establishment\":\"d\",\n",
    "  \"registered_capital\":\"e\",\n",
    "  \"office_address\":\"f\",\n",
    "  \"Company_profile\":\"g\"\n",
    "\n",
    "}}\n",
    "Extracted:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"requests_result\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = LLMRequestsChain(llm_chain=LLMChain(llm=llm, prompt=prompt))\n",
    "inputs = {\n",
    "  \"url\": \"https://vip.stock.finance.sina.com.cn/corp/go.php/vCI_CorpInfo/stockid/600519.phtml\"\n",
    "}\n",
    "\n",
    "response = chain(inputs)\n",
    "print(response['output'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T07:32:57.188547500Z",
     "start_time": "2024-02-28T07:32:40.248906600Z"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "id": "df6fa43bc9a80a4c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "结构化输出"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "8c83c75c021fe67a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=1)\n",
    "\n",
    "# 告诉他我们生成的内容需要哪些字段，每个字段类型式啥\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
    "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
    "]\n",
    "\n",
    "# 初始化解析器\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# 生成的格式提示符\n",
    "# {\n",
    "#\t\"bad_string\": string  // This a poorly formatted user input string\n",
    "#\t\"good_string\": string  // This is your response, a reformatted response\n",
    "#}\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "template = \"\"\"\n",
    "You will be given a poorly formatted string from a user.\n",
    "Reformat it and make sure all the words are spelled correctly\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% USER INPUT:\n",
    "{user_input}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "\n",
    "# 将我们的格式描述嵌入到 prompt 中去，告诉 llm 我们需要他输出什么样格式的内容\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# 使用解析器进行解析生成的内容\n",
    "chain.invoke({\"user_input\": \"welcom to china!\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T07:30:50.904974900Z",
     "start_time": "2024-02-28T07:30:48.755848100Z"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "id": "37202ce2ca1954cd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "执行多个chain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "74b4e482087a2e10"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m根据用户所在地区在中国，我推荐试试北京烤鸭。北京烤鸭是中国传统名菜之一，以其皮脆肉嫩、色泽诱人而闻名。它通常搭配薄薄的饼皮、葱、黄瓜等配菜一起食用，非常美味。北京烤鸭的制作过程独特，需要经过多道繁琐的工序，但结果绝对值得等待。如果有机会，不妨去北京尝尝正宗的北京烤鸭，一定会让你流连忘返的。\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m要在家制作北京烤鸭，首先需要准备好一只完整的鸭子。然后，将鸭子清洗干净，剁成块状，并用腌料腌制一段时间以增加味道。接着，将鸭子挂在烤炉上慢慢烤制，直到皮变得金黄脆口。最后，将烤好的鸭子切成薄片，搭配薄饼、葱、黄瓜等配菜一起食用。这样就可以在家品尝到美味的北京烤鸭了。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# location 链\n",
    "llm = ChatOpenAI(temperature=1)\n",
    "template = \"\"\"请根据用户所在地区提供一道当地的经典美食。\n",
    "% 用户所在地\n",
    "{user_location}\n",
    "\n",
    "你的回答:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
    "location_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# meal 链\n",
    "template = \"\"\"通过提供的菜肴名词, 请将要回答如何在家烹饪这道菜.\n",
    "% 菜肴\n",
    "{user_meal}\n",
    "\n",
    "你的回答:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
    "meal_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# 通过 SimpleSequentialChain 串联起来，第一个答案会被替换第二个中的user_meal，然后再进行询问\n",
    "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)\n",
    "review = overall_chain.run(\"中国\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T07:00:51.677906900Z",
     "start_time": "2024-02-28T07:00:42.106948700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "7a0499a2c96d5938",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用模型构建油管频道问答机器人"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "ef90400c8405c4b6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ChatVectorDBChain, ConversationalRetrievalChain\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "  ChatPromptTemplate,\n",
    "  SystemMessagePromptTemplate,\n",
    "  HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "# 加载 youtube 频道\n",
    "loader = YoutubeLoader.from_youtube_url('https://www.youtube.com/watch?v=Dj60HHy-Kqk')\n",
    "# 将数据转成 document\n",
    "documents = loader.load()\n",
    "\n",
    "# 初始化文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1000,\n",
    "  chunk_overlap=20\n",
    ")\n",
    "\n",
    "# 分割 youtube documents\n",
    "documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# 初始化 openai embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 将数据存入向量存储\n",
    "vector_store = Chroma.from_documents(documents, embeddings)\n",
    "\n",
    "# 通过向量存储初始化检索器\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "system_template = \"\"\"\n",
    "Use the following context to answer the user's question.\n",
    "If you don't know the answer, say you don't, don't try to make it up. And answer in Chinese.\n",
    "-----------\n",
    "{question}\n",
    "-----------\n",
    "{chat_history}\n",
    "\"\"\"\n",
    "\n",
    "# 构建初始 messages 列表，这里可以理解为是 openai 传入的 messages 参数\n",
    "messages = [\n",
    "  SystemMessagePromptTemplate.from_template(system_template),\n",
    "  HumanMessagePromptTemplate.from_template('{question}')\n",
    "]\n",
    "\n",
    "# 初始化 prompt 对象\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "\n",
    "# 初始化问答链\n",
    "qa = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0.1,max_tokens=2048),retriever,condense_question_prompt=prompt)\n",
    "\n",
    "\n",
    "chat_history = []\n",
    "while True:\n",
    "  question = input('问题：')\n",
    "  # 开始发送问题 chat_history 为必须参数,用于存储对话历史\n",
    "  result = qa({'question': question, 'chat_history': chat_history})\n",
    "  chat_history.append((question, result['answer']))\n",
    "  print(result['answer'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T06:52:09.879912500Z",
     "start_time": "2024-02-28T06:50:22.967087200Z"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "id": "c74a2fa9557830e5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "构建本地知识库问答机器人"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "f2db665cffe0fbbc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# 加载文件夹中的所有txt类型的文件\n",
    "loader = DirectoryLoader(r\"D:\\test\", glob='**/*.txt')\n",
    "# 将数据转成 document 对象，每个文件会作为一个 document\n",
    "documents = loader.load()\n",
    "\n",
    "# 初始化加载器\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "# 切割加载的 document\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 初始化 openai 的 embeddings 对象\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# 将 document 通过 openai 的 embeddings 对象计算 embedding 向量信息并临时存入 Chroma 向量数据库，用于后续匹配查询\n",
    "docsearch = Chroma.from_documents(split_docs, embeddings, persist_directory=r\"D:\\vector_store\")\n",
    "docsearch.persist()\n",
    "\n",
    "# 创建问答对象\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature=0), chain_type=\"stuff\", retriever=docsearch.as_retriever(), return_source_documents=True)\n",
    "# 进行问答\n",
    "result = qa({\"query\": \"孔乙己还欠多少个钱？\"})\n",
    "print(result)\n",
    "\n",
    "# 加载数据\n",
    "# docsearch = Chroma(persist_directory=\"D:/vector_store\", embedding_function=embeddings)\n",
    "query = \"孔乙己还欠多少个钱？\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)\n",
    "chain = load_qa_chain(ChatOpenAI(temperature=0), chain_type=\"stuff\", verbose=True)\n",
    "chain.run(input_documents=docs, question=query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T06:26:37.892288300Z",
     "start_time": "2024-02-28T06:26:29.128220100Z"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "id": "62308a0c3a038af6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "对超长文本进行总结"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "7d361e26dd624a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 导入文本\n",
    "loader = UnstructuredFileLoader(r\"D:\\dream.txt\")\n",
    "# 将文本转成 Document 对象\n",
    "document = loader.load()\n",
    "print(f'documents:{len(document)}')\n",
    "\n",
    "# 初始化文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "# 切分文本\n",
    "split_documents = text_splitter.split_documents(document)\n",
    "print(f'documents:{len(split_documents)}')\n",
    "\n",
    "# 加载 llm 模型\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 创建总结链\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True)\n",
    "\n",
    "# 执行总结链，（为了快速演示，只总结前5段）\n",
    "print(\"summary ********************\")\n",
    "chain.run(split_documents[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T06:01:40.174822100Z",
     "start_time": "2024-02-28T06:01:26.820474900Z"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "id": "f3feacf9d4e0ba97",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过 Google 搜索并返回答案"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "141ce4f2508e6dae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "# 加载 OpenAI 模型\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    " # 加载 serpapi 工具\n",
    "tools = load_tools([\"serpapi\"])\n",
    "\n",
    "# 如果搜索完想再计算一下可以这么写\n",
    "# tools = load_tools(['serpapi', 'llm-math'], llm=llm)\n",
    "\n",
    "# 如果搜索完想再让他再用python的print做点简单的计算，可以这样写\n",
    "# tools=load_tools([\"serpapi\",\"python_repl\"])\n",
    "\n",
    "# 工具加载后都需要初始化，verbose 参数为 True，会打印全部的执行详情\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# 运行 agent\n",
    "agent.run(\"What's the date today? What great events have taken place today in history?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T03:32:36.573921700Z",
     "start_time": "2024-02-28T03:32:24.515110200Z"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "id": "3cad89435308f5bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "调用OpenAI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "8d195ee3432e641a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that translates English to Chinese.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Translate this sentence from English to French. I love programming.\"\n",
    "    ),\n",
    "]\n",
    "chat(messages)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T03:32:36.617128600Z",
     "start_time": "2024-02-28T03:32:36.571924500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "263c9b7b8ece32c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}